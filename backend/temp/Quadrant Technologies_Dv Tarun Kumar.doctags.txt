<doctag><section_header_level_1><loc_61><loc_46><loc_240><loc_54>TARUN KUMAR DEGALA</section_header_level_1>
<section_header_level_1><loc_61><loc_64><loc_182><loc_69>Associate Data Scientist</section_header_level_1>
<text><loc_61><loc_78><loc_204><loc_84>Email: dvtarun1@gmail.com</text>
<text><loc_61><loc_91><loc_189><loc_96>Mobile: +91 7799200960</text>
<text><loc_61><loc_104><loc_403><loc_111>LinkedIn: linkedin.com/in/tarun-kumar-degala-venkata-7419061a5</text>
<section_header_level_1><loc_61><loc_132><loc_187><loc_142>Career Objective</section_header_level_1>
<text><loc_61><loc_167><loc_443><loc_197>To apply my deep technical expertise and innovative problem-solving capabilities in a dynamic, forward-thinking organization. Committed to continuous professional development, I excel in collaborative environments and have a proven ability to communicate complex, data-driven insights.</text>
<section_header_level_1><loc_62><loc_222><loc_230><loc_233>Professional Summary</section_header_level_1>
<unordered_list><list_item><loc_76><loc_256><loc_317><loc_262> GCP Certified Professional Machine Learning Engineer</list_item>
<list_item><loc_76><loc_264><loc_263><loc_270> GCP Certified Professional Data Engineer</list_item>
<list_item><loc_76><loc_271><loc_246><loc_277> Proficient in conversational Japanese</list_item>
<list_item><loc_76><loc_278><loc_309><loc_284> Total 6+ years of experience in AI, ML, and Python.</list_item>
<list_item><loc_76><loc_285><loc_299><loc_291> 4+ years of experience in Google Cloud Platform.</list_item>
<list_item><loc_76><loc_293><loc_322><loc_298> 4 Years experience Natural Language Processing (NLP)</list_item>
<list_item><loc_76><loc_300><loc_443><loc_313> 4 Year Experience in (GenAI) including areas such as prompt engineering, and prompt tuning.</list_item>
<list_item><loc_76><loc_314><loc_443><loc_327> Extensive Experience on working with Google Gemini API, GPT, Dall-E , and Large Language Models such as BERT and PaLM</list_item>
<list_item><loc_76><loc_329><loc_348><loc_335> Skilled in utilizing AutoML for automated model development</list_item>
<list_item><loc_76><loc_336><loc_442><loc_349> Expertise in deploying models using Cloud Functions, App Engine, Kubernetes Engine, and Cloud Run .</list_item>
<list_item><loc_76><loc_350><loc_443><loc_364> Proficient in leveraging Cloud Storage, BigQuery, Dataflow, Dataproc, and Data Fusion for efficient data engineering and storage</list_item>
<list_item><loc_76><loc_366><loc_442><loc_380> Hands -on experience with Vertex AI, AI Platform Training, and AI Platform Prediction for building, training, and deploying machine learning models.</list_item>
<list_item><loc_76><loc_382><loc_442><loc_395> Experience with Cloud Composer, monitoring with Cloud Monitoring, and ensuring security with Cloud Security Command Centre and Cloud IAM .</list_item>
<list_item><loc_76><loc_397><loc_338><loc_403> Experience in building chat-bots using Google Dialog Flow .</list_item>
<list_item><loc_76><loc_404><loc_443><loc_417> Expert in Python machine learning and deep learning libraries such as Tensorflow, Keras, NLTK, Spacy, NumPy, Pandas , and Matplotlib .</list_item>
<list_item><loc_76><loc_419><loc_179><loc_425> Highly Skilled in SQL</list_item>
</unordered_list>
<page_break>
<section_header_level_1><loc_77><loc_45><loc_115><loc_54>Skills</section_header_level_1>
<otsl><loc_86><loc_84><loc_427><loc_240><ched>Operating System<ched>Windows<nl><fcel>Languages<fcel>Python 3.13, C, SQL<nl><fcel>IDES<fcel>Spyder, Jupyter, Visual Studio Code, and Google  Collaboratory (Colab)<nl><fcel>Frameworks<fcel>TensorFlow, Keras, Kubernetes, Docker<nl><fcel>Artificial Intelligence<fcel>Generative AI, Prompt Engineering, Prompt Tuning,  Hyper Parameter Tuning, Large Language Models(LLM)  like BERT, PaLM, Gemini API, Google DialogFlow ,  Natural Language Processing.<nl><fcel>GCP Services<fcel>Vertex AI, Cloud AutoML, AI Platform, BigQuery, Cloud  Storage, Compute Engine, Cloud Functions, App Engine,  Bigtable, Cloud Endpoints, Cloud Firestore, Cloud  Logging, Cloud Monitoring, Cloud Natural Language API,  Cloud Run, Cloud Scheduler, Cloud Search, Cloud  Spanner, Cloud Text-to-Speech API, Cloud Translation  API, Compute Engine, Data Catalog, Data Fusion,  Dataflow, Dataproc, Deployment Manager, Dialogflow,  Endpoint API, Error Reporting, Firebase, Logging<nl></otsl>
<section_header_level_1><loc_62><loc_267><loc_239><loc_277>Professional Experience</section_header_level_1>
<otsl><loc_60><loc_305><loc_420><loc_345><fcel>Name of the Project<fcel>Transcription Service<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, Speech to Text API, Cloud Storage, PLX Scripts, Google Collaboratory (Colab)<nl><caption><loc_66><loc_296><loc_212><loc_301>Project:1 -Company Name: Accenture</caption></otsl>
<section_header_level_1><loc_61><loc_358><loc_154><loc_364>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_370><loc_442><loc_383> To provide a unified and highly accurate transcription service empowering businesses to unlock valuable audio insights.</list_item>
<list_item><loc_76><loc_384><loc_442><loc_397> To build configurable, unified service broadening its potential applications and making it more adaptable to diverse needs.</list_item>
<list_item><loc_76><loc_399><loc_442><loc_412> To expand language support with better accuracy by model adaptation and other approaches</list_item>
<list_item><loc_76><loc_413><loc_442><loc_426> To baseline quality metrics for 10+ languages across clients and continuously measure quality, integrating API with ML foundations.</list_item>
<list_item><loc_76><loc_428><loc_442><loc_441> Incorporate a user -friendly widget providing a more intuitive and insightful user experience, including side by side audio and transcripts.</list_item>
</unordered_list>
<page_break>
<section_header_level_1><loc_61><loc_44><loc_186><loc_50>Roles and Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_56><loc_443><loc_77> Improve application capabilities through transcript translation, multi-language transcription, audio dubbing content filtering, and speaker diarization (detecting different speakers in an audio recording).</list_item>
<list_item><loc_76><loc_78><loc_265><loc_84> Improving Advanced Language Support:</list_item>
<list_item><loc_106><loc_85><loc_436><loc_91>o Improving language detection by configuring agent self-language settings.</list_item>
<list_item><loc_76><loc_92><loc_188><loc_98> Quality Improvements:</list_item>
<list_item><loc_106><loc_99><loc_303><loc_105>o Adaptation of new models and approaches.</list_item>
<list_item><loc_106><loc_107><loc_301><loc_113>o Editing Transcripts and refining the model.</list_item>
<list_item><loc_76><loc_114><loc_160><loc_120> Quality Insights:</list_item>
<list_item><loc_106><loc_121><loc_297><loc_127>o Automated Transcription Quality Insights.</list_item>
<list_item><loc_76><loc_128><loc_229><loc_134> Advanced Transcription Support:</list_item>
<list_item><loc_106><loc_136><loc_363><loc_141>o Worked on bi -directional real time transcript translations.</list_item>
<list_item><loc_106><loc_143><loc_356><loc_149>o Worked on user UI(widget) for transcribed audio player</list_item>
<list_item><loc_76><loc_150><loc_222><loc_155> Worked on Advanced Features:</list_item>
<list_item><loc_106><loc_157><loc_218><loc_163>o Transcript search API's</list_item>
<list_item><loc_106><loc_165><loc_276><loc_170>o Audio and transcript content filtering</list_item>
<list_item><loc_106><loc_172><loc_212><loc_178>o Speaker identification</list_item>
<list_item><loc_106><loc_179><loc_202><loc_185>o Speaker attribution</list_item>
<list_item><loc_106><loc_186><loc_278><loc_192>o Re-transcription and model switching</list_item>
<list_item><loc_106><loc_194><loc_221><loc_199>o Automatic punctuations</list_item>
<list_item><loc_76><loc_201><loc_114><loc_205> Audio</list_item>
<list_item><loc_106><loc_208><loc_422><loc_214>o Worked on audio dubbing and translation within audio recording player</list_item>
<list_item><loc_106><loc_215><loc_330><loc_221>o Designed model to use ML foundation capabilities</list_item>
<list_item><loc_76><loc_222><loc_271><loc_228> Worked on Quality metrics and dashboard.</list_item>
</unordered_list>
<otsl><loc_60><loc_256><loc_420><loc_296><ched>Name of the Project<ched>Niki<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, BERT, Google Colaboratory (Colab), BigQuery,  Large Language Models.<nl><caption><loc_66><loc_247><loc_212><loc_252>Project:2 -Company Name: Accenture</caption></otsl>
<section_header_level_1><loc_61><loc_309><loc_154><loc_315>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_321><loc_443><loc_340> Leveraging email intent detection and instant response technologies for optimizing FinX's operational efficiency and customer deflection. It is a continuously evolving classification model.</list_item>
<list_item><loc_76><loc_342><loc_442><loc_355> Providing Customer support solution to salesforce where 40% of the cases will be answered quickly out of 600k cases.</list_item>
</unordered_list>
<section_header_level_1><loc_61><loc_362><loc_186><loc_367>Roles and Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_374><loc_315><loc_379> Improved accuracy of the model from 74% to 87% .</list_item>
<list_item><loc_76><loc_381><loc_442><loc_393> Improved deflection rate through model refinements and tailored confidence scores.</list_item>
<list_item><loc_76><loc_395><loc_443><loc_416> Worked on automatic email generation which provides an automated email response, either a canned response or a link to the portal that enables users to lookup information.</list_item>
<list_item><loc_76><loc_417><loc_310><loc_423> Extract information from email body to enrich cases</list_item>
<list_item><loc_76><loc_424><loc_272><loc_430> Continued support for the deployed model.</list_item>
</unordered_list>
<page_break>
<otsl><loc_59><loc_43><loc_420><loc_101><fcel>Project:3  -  Company Name: Accenture<lcel><nl><fcel>Name of the Project<fcel>Data Analytics Solutions<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, Gemini API , Generative AI, Prompt Engineering  SQL, Google Cloud Platform (Vertex AI, Big Query), Google  Colaboratory (Colab), PLX Dashboard,<nl></otsl>
<section_header_level_1><loc_61><loc_114><loc_154><loc_120>Project Description:</section_header_level_1>
<text><loc_61><loc_126><loc_443><loc_161>Engineered a data quality assurance framework leveraging Gemini API. This solution automates the identification of data quality issues, including uniqueness, data type conformity, completeness, consistency, and timeliness. By analyzing complex datasets and extracting patterns, the framework generates comprehensive reports to empower datadriven decision -making.</text>
<section_header_level_1><loc_61><loc_167><loc_186><loc_173>Roles and Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_179><loc_442><loc_192> Engineered and deployed a data quality framework using Gemini API to identify and flag violations.</list_item>
<list_item><loc_76><loc_193><loc_362><loc_199> Leveraged Python libraries for data preprocessing and analysis.</list_item>
<list_item><loc_76><loc_201><loc_442><loc_213> Implemented prompt engineering techniques to extract precise data quality rules from Gemini.</list_item>
<list_item><loc_76><loc_215><loc_346><loc_221> Utilized BigQuery for efficient data querying and extraction.</list_item>
<list_item><loc_76><loc_222><loc_439><loc_235> Fine-tuned machine learning models using advanced techniques like chain-ofthought reasoning.</list_item>
<list_item><loc_76><loc_237><loc_393><loc_243> Developed interactive PLX dashboards to visualize data quality insights.</list_item>
</unordered_list>
<section_header_level_1><loc_66><loc_256><loc_212><loc_262>Project:4 -Company Name: Accenture</section_header_level_1>
<otsl><loc_59><loc_265><loc_420><loc_305><ched>Name of the Project<ched>Databot<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, Gemini API , Generative AI, Prompt Engineering , Dialog Flow,  ,  Google Cloud Platform (Vertex AI)<nl></otsl>
<section_header_level_1><loc_61><loc_319><loc_154><loc_324>Project Description:</section_header_level_1>
<text><loc_61><loc_331><loc_443><loc_351>Engineered a sophisticated chatbot leveraging GenAI and Dialogflow to facilitate natural language interactions with complex datasets. The chatbot efficiently processes user input, executes complex queries, and presents relevant information in a user-friendly format.</text>
<section_header_level_1><loc_61><loc_357><loc_186><loc_363>Roles and Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_369><loc_442><loc_382> Designed and implemented a robust knowledge base and prompt engineering strategies for the chatbot.</list_item>
<list_item><loc_76><loc_383><loc_442><loc_395> Built a user -friendly Dialog flow chatbot to enable natural language interaction with the data.</list_item>
<list_item><loc_76><loc_398><loc_442><loc_410> Developed a front-end interface to facilitate seamless user engagement with the chatbot.</list_item>
<list_item><loc_76><loc_412><loc_383><loc_418> Rigorously tested and chatbot for optimal performance and accuracy.</list_item>
</unordered_list>
<page_break>
<otsl><loc_59><loc_54><loc_420><loc_94><fcel>Name of the Project<fcel>DLP<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.9,HTML,CSS,Google cloud platform, Google  AppsScript, Generative AI, Big Query, Vertex AI, Colab<nl><caption><loc_66><loc_45><loc_212><loc_50>Project:5 -Company Name: Accenture</caption></otsl>
<section_header_level_1><loc_68><loc_111><loc_164><loc_116>Project Description:</section_header_level_1>
<text><loc_67><loc_127><loc_436><loc_141>The client wants to incorporate a tool that conducts sentiment analysis, as well as a Dialogflow chatbot that provides sentiment analysis for user queries.</text>
<text><loc_67><loc_148><loc_429><loc_170>Improving the performance and accuracy of the system by implementing Gemini API andGenerative AI -related technology such as prompt engineering and prompt tuning.</text>
<text><loc_67><loc_177><loc_433><loc_191>Working on Large Language Models (LLMs) like BERT, PaLM and fine-tuning them usingtechniques such as LoRA tuning and hyper-parameter tuning.</text>
<section_header_level_1><loc_68><loc_202><loc_188><loc_208>Roles & Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_219><loc_243><loc_224> Working on LLM along with prompts</list_item>
<list_item><loc_76><loc_226><loc_159><loc_232> Prompt Creation</list_item>
<list_item><loc_76><loc_233><loc_150><loc_239> Prompt tuning</list_item>
<list_item><loc_76><loc_240><loc_314><loc_246> Designing and implementing Large Language Models</list_item>
<list_item><loc_76><loc_248><loc_170><loc_253> Preprocessing data</list_item>
<list_item><loc_76><loc_255><loc_234><loc_261> Improving training methodologies</list_item>
<list_item><loc_76><loc_262><loc_442><loc_275> Fine-tuning the models to improve their accuracy and precision using techniques like LoRa tuning, soft attention and hyper parameter tuning.</list_item>
<list_item><loc_76><loc_276><loc_311><loc_282> Creating Dialogflow chatbots to resolve user queries</list_item>
<list_item><loc_76><loc_284><loc_384><loc_290> Working on labelling and annotating the data provided by the models</list_item>
<list_item><loc_76><loc_291><loc_269><loc_297> Monitoring the performance of the models</list_item>
</unordered_list>
<otsl><loc_60><loc_313><loc_420><loc_365><fcel>Project:6  -  Company Name: Accenture<lcel><nl><fcel>Name of the Project<fcel>Vertex AI Templates<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, BERT, Vertex AI, Jupyter, Cloud Storage,  BigQuery<nl></otsl>
<section_header_level_1><loc_68><loc_381><loc_164><loc_387>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_83><loc_398><loc_408><loc_412> Engineered Vertex AI-based templates to streamline the development of regression, clustering, and classification models.</list_item>
<list_item><loc_83><loc_414><loc_436><loc_428> Enhanced semantic analysis capabilities with Distilled BERT-based templates to improve decision-making and customer experience.</list_item>
</unordered_list>
<page_break>
<section_header_level_1><loc_61><loc_44><loc_181><loc_50>Roles & Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_61><loc_442><loc_74> Collaborated with cross -functional teams (e.g., data engineers, product managers) to understand business requirements and translate them into technical solutions.</list_item>
<list_item><loc_76><loc_75><loc_442><loc_88> Created and refined reusable templates to accelerate model development and deployment.</list_item>
<list_item><loc_76><loc_90><loc_259><loc_96> Optimized model performance and accuracy</list_item>
<list_item><loc_76><loc_98><loc_352><loc_104> Cleansed, transformed, and prepared data for model training.</list_item>
<list_item><loc_76><loc_105><loc_413><loc_111> Conducted exploratory data analysis (EDA) to identify patterns and insights.</list_item>
<list_item><loc_76><loc_112><loc_357><loc_118> Documented model development processes and best practices.</list_item>
</unordered_list>
<otsl><loc_60><loc_134><loc_420><loc_186><fcel>Project:7  -  Company Name: Accenture<lcel><nl><fcel>Name of the Project<fcel>CORTEX Prediction of lead time for goods<nl><fcel>Job Title<fcel>Ind & Func AI Decision Science Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, Big Query, Kubeflow, AutoML, BQML, Vertex AI,  Cloud Endpoints<nl></otsl>
<section_header_level_1><loc_68><loc_202><loc_164><loc_208>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_219><loc_442><loc_232> Develop a baseline AUTOML regression model on the Google cloud environment to predict the lead time for products in SAP environment.</list_item>
<list_item><loc_76><loc_233><loc_442><loc_246> Streamline data pipelines using Kubeflow to automate data ingestion and model training, reducing manual effort and increasing accuracy.</list_item>
<list_item><loc_76><loc_248><loc_373><loc_254> Create Vertex AI Endpoint, Implement batch and online prediction.</list_item>
</unordered_list>
<section_header_level_1><loc_70><loc_267><loc_185><loc_273>Roles & Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_279><loc_323><loc_285> Collaborated with stakeholders to define requirements.</list_item>
<list_item><loc_76><loc_286><loc_439><loc_292> Developed an AutoML regression model on GCP to predict SAP product lead times.</list_item>
<list_item><loc_76><loc_293><loc_442><loc_306> Orchestrated data pipelines using Kubeflow to automate data ingestion and model training.</list_item>
<list_item><loc_76><loc_308><loc_442><loc_321> Implemented model monitoring and alerting mechanisms to ensure model performance.</list_item>
<list_item><loc_76><loc_322><loc_392><loc_328> Stored batch prediction results in BigQuery for dashboarding in Looker.</list_item>
<list_item><loc_76><loc_329><loc_442><loc_341> Utilized online predictions to gain insights into feature importance and model behavior.</list_item>
<list_item><loc_76><loc_344><loc_443><loc_357> Leveraged BigQuery ML to deliver accurate and timely insights, driving data-driven decision -making.</list_item>
<list_item><loc_76><loc_358><loc_442><loc_371> Utilized BigQuery's powerful querying capabilities to extract valuable information from large datasets.</list_item>
<list_item><loc_76><loc_373><loc_290><loc_379> Generate Synthetic data using Python libraries .</list_item>
<list_item><loc_76><loc_380><loc_364><loc_386> Triggering dags in Airflow, pylinting of code, mock data creation.</list_item>
</unordered_list>
<page_break>
<otsl><loc_60><loc_42><loc_420><loc_94><fcel>Project:8  -  Company Name: Tech Mahindra<lcel><nl><fcel>Name of the Project<fcel>Sales Forecasting for Pharma Client<nl><fcel>Job Title<fcel>Associate Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13, Jupyter Notebook ,  Pandas, NumPy, Scikit-learn,  Statsmodels<nl></otsl>
<section_header_level_1><loc_68><loc_111><loc_164><loc_116>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_83><loc_127><loc_385><loc_133> To accurately forecast sales for multiple products using Arima Model</list_item>
<list_item><loc_83><loc_135><loc_430><loc_158> Effectively capturing and modelling seasonal trends, the model will enable businesses to optimize inventory levels, improve production planning, and make informed decisions to drive revenue growth.</list_item>
</unordered_list>
<section_header_level_1><loc_67><loc_169><loc_182><loc_174>Roles & Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_83><loc_184><loc_427><loc_198> Collaborate with business stakeholders to understand their forecasting needs and translate them into actionable insights</list_item>
<list_item><loc_83><loc_201><loc_424><loc_215> Gather historical sales data for multiple products from various sources (e.g., ERP systems, CRM systems, spreadsheets).</list_item>
<list_item><loc_83><loc_217><loc_405><loc_230> Cleanse and preprocess the data to handle missing values, outliers, and inconsistencies.</list_item>
<list_item><loc_83><loc_234><loc_434><loc_248> Implement an ARIMA model to capture the time series components (trend, seasonality, and residual).</list_item>
<list_item><loc_83><loc_250><loc_442><loc_265> Experiment with different model configurations (e.g., ARIMA(p,d,q)(P,D,Q)s) to find the optimal parameters.</list_item>
<list_item><loc_83><loc_267><loc_440><loc_290> Evaluate model performance using appropriate metrics (e.g., Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE)).</list_item>
</unordered_list>
<otsl><loc_59><loc_322><loc_420><loc_362><fcel>Name of the Project<fcel>Customer Churn prediction for an Insurance company<nl><fcel>Job Title<fcel>Associate Analyst<nl><fcel>Tools and  Environment<fcel>Python 3.13,<nl><caption><loc_66><loc_313><loc_230><loc_318>Project:9 -Company Name: Tech Mahindra</caption></otsl>
<section_header_level_1><loc_68><loc_379><loc_164><loc_384>Project Description:</section_header_level_1>
<unordered_list><list_item><loc_83><loc_395><loc_430><loc_401> Develop a KNN-based churn prediction model to identify at-risk customers .</list_item>
<list_item><loc_83><loc_403><loc_417><loc_418> Utilize K -means clustering to identify distinct customer segments based on behavioural and demographic characteristics.</list_item>
</unordered_list>
<page_break>
<section_header_level_1><loc_61><loc_44><loc_176><loc_50>Roles & Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_76><loc_56><loc_442><loc_69> Gather and clean customer data from various sources (e.g., CRM, transactional data).</list_item>
<list_item><loc_76><loc_71><loc_377><loc_77> Feature engineer relevant variables to improve model performance.</list_item>
<list_item><loc_76><loc_78><loc_442><loc_91> Develop a KNN-based churn prediction model to identify customers at risk of churning.</list_item>
<list_item><loc_76><loc_92><loc_443><loc_105> Experiment with different hyper-parameters (e.g., number of neighbors, distance metric) to optimize model performance.</list_item>
<list_item><loc_76><loc_107><loc_442><loc_120> Apply K-means clustering to segment customers based on their behavior and demographics.</list_item>
<list_item><loc_76><loc_121><loc_442><loc_134> Analyze the characteristics of each customer segment to identify opportunities for targeted marketing and retention strategies.</list_item>
<list_item><loc_76><loc_136><loc_442><loc_149> Communicate findings and recommendations effectively through clear visualizations and reports.</list_item>
<list_item><loc_76><loc_150><loc_442><loc_163> Present insights to decision-makers and provide guidance on how to leverage the model to improve customer retention.</list_item>
</unordered_list>
<section_header_level_1><loc_76><loc_178><loc_319><loc_186>Certifications and Achievements</section_header_level_1>
<unordered_list><list_item><loc_76><loc_206><loc_317><loc_212> GCP Certified Professional Machine Learning Engineer</list_item>
<list_item><loc_76><loc_213><loc_263><loc_219> GCP Certified Professional Data Engineer</list_item>
<list_item><loc_76><loc_221><loc_250><loc_226> Proficient in Conversational Japanese.</list_item>
<list_item><loc_76><loc_229><loc_278><loc_234> Won prizes in multiple football tournaments.</list_item>
<list_item><loc_76><loc_236><loc_443><loc_248> Honored with an award for exceptional athleticism and teamwork in the inter-sports football tournament .</list_item>
</unordered_list>
<section_header_level_1><loc_77><loc_268><loc_212><loc_278>Languages Known</section_header_level_1>
<otsl><loc_67><loc_307><loc_419><loc_380><ched>Language<ched>Proficiency<nl><fcel>English<fcel>Fluent<nl><fcel>Hindi<fcel>Fluent<nl><fcel>Telugu<fcel>Native Language<nl><fcel>Japanese<fcel>Conversational<nl></otsl>
</doctag>
<doctag><section_header_level_1><loc_157><loc_51><loc_241><loc_57>Azure Data Engineer</section_header_level_1>
<section_header_level_1><loc_59><loc_76><loc_118><loc_82>Job Description:</section_header_level_1>
<text><loc_60><loc_93><loc_431><loc_99>Please find below the Job description for Azure Data Engineer requirement. Request for your support.</text>
<text><loc_59><loc_111><loc_222><loc_142>Position: Azure Data Engineer Experience: 5 – 8 years Job location: Hyderabad / Bangalore (Hybrid) Notice Period – – 0 - 15 days MAX.</text>
<section_header_level_1><loc_74><loc_153><loc_407><loc_159>➢ L1 or L2 any one round must be in- person from Bangalore / Hyderabad office.</section_header_level_1>
<text><loc_59><loc_170><loc_400><loc_185>Mandatory Skills: SQL Server, Azure Synapse / Pyspark , Azure Data Factory, y, Azure Databricks. Tabular modeling .</text>
<text><loc_59><loc_196><loc_216><loc_202>Added Advantage - Power BI /DAX queries .</text>
<section_header_level_1><loc_59><loc_221><loc_118><loc_227>Job Description:</section_header_level_1>
<text><loc_59><loc_230><loc_442><loc_272>As an Azure Data Engineer, you will be expected to design, implement, and manage data solutions on the Microsoft Azure cloud platform. The ideal candidate will have a proven track record of writing complex SQL stored procedures with implementing OTLP database solutions (using Microsoft SQL Server) . As well as experience with Azure Synapse / PySpark / Azure Databricks for big data processing.</text>
<section_header_level_1><loc_59><loc_284><loc_134><loc_290>Key Responsibilities:</section_header_level_1>
<unordered_list><list_item><loc_74><loc_302><loc_412><loc_317>Collaborate with cross -functional teams to gather, analyze, and document business requirements for data integration projects.</list_item>
<list_item><loc_74><loc_321><loc_398><loc_336>Expertise in T-SQL, Dynamic SQL, Spark SQL, and ability to write complex stored procedures.</list_item>
<list_item><loc_74><loc_340><loc_409><loc_355>Write complex stored procedures to support data transformation and to implement business validation logic.</list_item>
<list_item><loc_74><loc_358><loc_443><loc_374>Experience in writing notebooks in Azure Synapse/Databricks using Spark SQL or PySpark to process and analyse large volumes of data</list_item>
<list_item><loc_74><loc_377><loc_430><loc_392>Develop and maintain robust data pipelines using Azure Data Factory ensuring seamless data flow between systems.</list_item>
<list_item><loc_74><loc_396><loc_234><loc_402>Strong algorithmic programming skills</list_item>
<list_item><loc_74><loc_406><loc_409><loc_421>Work closely with the team to ensure data quality, integrity, and accuracy across all systems.</list_item>
<list_item><loc_74><loc_424><loc_408><loc_439>Experience on OLTP (Online Transaction Processing) systems using SQL Server and contribute to their enhancement and optimization.</list_item>
</unordered_list>
<picture><loc_363><loc_22><loc_427><loc_50></picture>
<page_break>
<section_header_level_1><loc_59><loc_111><loc_112><loc_116>Qualifications:</section_header_level_1>
<text><loc_60><loc_128><loc_357><loc_143>Bachelor's degree in Computer Science, Information Technology, or a related field. Hands -on experience in writing complex T-SQL queries and stored procedures</text>
<text><loc_59><loc_154><loc_300><loc_185>Good experience in data integration and database development. Proficiency in T-SQL and Spark SQL/PySpark . (Synapse/ Databricks) Extensive experience with Azure Data Factory Excellent problem-solving skills and attention to detail</text>
<picture><loc_363><loc_22><loc_427><loc_50></picture>
</doctag>